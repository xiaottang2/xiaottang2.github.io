<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>构建数据科学的作品集：从机器学习项目开始 | Xiaoting Tang&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="##构建数据科学的作品集：从机器学习项目开始
本文是如何建立数据科学作品的第三步曲。如果你喜欢并想要知本系列的下一篇文章什么时候发布，可以在文末订阅。
数据科学公司在决定是否雇佣的时候越来越看重应聘者的作品集。其中一个原因是作品集是最好判断一个人的真实技能的方法。好消息是你的作品集其实完全在你掌控之中。如果你花精力在上面，你就可以做出一个让公司刮目相看的作品集。
建立一个高质量的作品的第一步是要知">
<meta property="og:type" content="article">
<meta property="og:title" content="构建数据科学的作品集：从机器学习项目开始">
<meta property="og:url" content="http://yoursite.com/2016/09/21/data-sceince-portfolio-machine-learning-project/index.html">
<meta property="og:site_name" content="Xiaoting Tang's Blog">
<meta property="og:description" content="##构建数据科学的作品集：从机器学习项目开始
本文是如何建立数据科学作品的第三步曲。如果你喜欢并想要知本系列的下一篇文章什么时候发布，可以在文末订阅。
数据科学公司在决定是否雇佣的时候越来越看重应聘者的作品集。其中一个原因是作品集是最好判断一个人的真实技能的方法。好消息是你的作品集其实完全在你掌控之中。如果你花精力在上面，你就可以做出一个让公司刮目相看的作品集。
建立一个高质量的作品的第一步是要知">
<meta property="og:image" content="https://www.dataquest.io/blog/images/end_to_end/github.png">
<meta property="og:image" content="https://www.dataquest.io/blog/images/end_to_end/foreclosure.jpg">
<meta property="og:image" content="https://www.dropbox.com/s/f0ld1ztm7w5lim6/Screenshot%202016-09-29%2021.56.18.png?raw=1">
<meta property="og:image" content="https://www.dropbox.com/s/cy5mueqz7vgxxa2/Screenshot%202016-09-29%2022.40.02.png?raw=1">
<meta property="og:image" content="https://www.dropbox.com/s/fumpjfvbim1ot9d/Screenshot%202016-09-29%2022.41.22.png?raw=1">
<meta property="og:image" content="https://www.dropbox.com/s/vauljb4xp2qnz7n/Screenshot%202016-09-29%2023.16.57.png?raw=1">
<meta property="og:updated_time" content="2016-09-29T16:26:33.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="构建数据科学的作品集：从机器学习项目开始">
<meta name="twitter:description" content="##构建数据科学的作品集：从机器学习项目开始
本文是如何建立数据科学作品的第三步曲。如果你喜欢并想要知本系列的下一篇文章什么时候发布，可以在文末订阅。
数据科学公司在决定是否雇佣的时候越来越看重应聘者的作品集。其中一个原因是作品集是最好判断一个人的真实技能的方法。好消息是你的作品集其实完全在你掌控之中。如果你花精力在上面，你就可以做出一个让公司刮目相看的作品集。
建立一个高质量的作品的第一步是要知">
<meta name="twitter:image" content="https://www.dataquest.io/blog/images/end_to_end/github.png">
  
    <link rel="alternate" href="/atom.xml" title="Xiaoting Tang&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Xiaoting Tang&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-data-sceince-portfolio-machine-learning-project" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/21/data-sceince-portfolio-machine-learning-project/" class="article-date">
  <time datetime="2016-09-21T13:38:24.000Z" itemprop="datePublished">2016-09-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      构建数据科学的作品集：从机器学习项目开始
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>##构建数据科学的作品集：从机器学习项目开始</p>
<p>本文是如何建立数据科学作品的第三步曲。如果你喜欢并想要知本系列的下一篇文章什么时候发布，可以<a href="https://www.dataquest.io/blog/data-science-portfolio-machine-learning/#email-signup" target="_blank" rel="external">在文末订阅</a>。</p>
<p>数据科学公司在决定是否雇佣的时候越来越看重应聘者的作品集。其中一个原因是作品集是最好判断一个人的真实技能的方法。好消息是你的作品集其实完全在你掌控之中。如果你花精力在上面，你就可以做出一个让公司刮目相看的作品集。</p>
<p>建立一个高质量的作品的第一步是要知道要展示哪些技能。公司想要数据科学家拥有的最主要的技能，也就是他们想你的作品集展示的最主要的技能，有下面这些：</p>
<ul>
<li>交流能力</li>
<li>与他人协作的能力</li>
<li>技术竞争力</li>
<li>能合理解释数据的能力</li>
<li>积极主动的动力和能力</li>
</ul>
<p>任何好的作品集都是由数个项目构成的，每一个项目可能展示1-2个上面提到的技能。本文是讲述如何建立一个丰满的数据科学作品集的第三步曲。本文将涵盖如何制作你作品集里的第二个项目，和如何从头到尾地建立一个机器学习项目。在最后，你会拥有一个可以展示你合理解释数据能力和技术竞争力的项目。如果你想一窥项目全貌的话，<a href="https://github.com/dataquestio/loan-prediction" target="_blank" rel="external">这里</a>是完整的项目文件。</p>
<p>#一个从头到尾的项目</p>
<p>作为一个数据科学家，有时候你会被叫去拿一个数据集然后想方设法用数据<a href="https://www.dataquest.io/blog/data-science-portfolio-project/" target="_blank" rel="external">说一个故事</a>。这些时候，良好的沟通和理清你的思路是非常重要的。像我们在之前提到的Jupyter notebook这样的工具就能很好地帮助你做这件事。一个预期结果是你最终递交出一个报告，或者一个总结你发现的文档。</p>
<p>然而，也有时候你会被叫去做一个有运营价值的项目。一个有运营价值的项目会直接影响一个公司的日常运营，而且经常会被许多人使用多次。一个像这样的任务可能会是“设计一个可以预测我们用户变动率的算法”， 或者是“创建一个可以自动给我们的文章标签的模型”。在这样的情况下，讲故事的能力就没有技术竞争力重要了。你需要能够拿到一个数据集，理解它，然后写一些可以处理这些数据的脚本。经常很重要的是这些脚本要花最小的系统资源，比如内存，还要运行得很快。很常见的事是这些脚本会被运行多次，所以最终的交付品就变成了这些脚本自身，而不是报告。这些成果经常都会和运营流程综合在一起，甚至可能是直接面对用户的。</p>
<p>建立从头到尾的项目的主要构成有：</p>
<ul>
<li>理解整个项目环境</li>
<li>探索数据并找到其中的细微差别</li>
<li>建立一个结构良好的项目，使得其和运营流程结合很简单</li>
<li>写出既运行快又占用最少系统资源的高性能代码</li>
<li>为你的代码的安装和使用写出良好的文档，让其他人也能使用</li>
</ul>
<p>为了高效地建立这样的项目，我们会需要和许多文件打交道。我们非常推荐使用像<a href="https://atom.io/" target="_blank" rel="external">Atom</a>的文档编辑器，或者像<a href="https://www.jetbrains.com/pycharm/" target="_blank" rel="external">PyCharm</a>一样的IDE。这些工具允许你在不同文件间跳转，并且可以编辑不同类型的文件，比如markdown文件，Python文件和csv文件。给你的代码建立结构，使得版本管理和上传到像<a href="https://github.com/" target="_blank" rel="external">Github</a>这样的代码协作工具变得简单，也是很有帮助的。</p>
<p><img src="https://www.dataquest.io/blog/images/end_to_end/github.png" alt=""><br><em>在Github上的该项目</em></p>
<p>在本文中，我们会使用比如<a href="http://pandas.pydata.org/" target="_blank" rel="external">Pandas</a>和<a href="http://scikit-learn.org/" target="_blank" rel="external">scikit-learn</a>这样的库。我们会特别多地用到Pandas的<a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html" target="_blank" rel="external">DataFrame</a>，这会使得读取数据和用Python处理扁平数据更简单。</p>
<p>#找到好的数据集</p>
<p>一个对于有头有尾的项目有利的数据集可能会很难找。这个数据集需要足够大，这样才能体现内存和性能的限制。它也需要潜在地对运营方面有用。举个例子，<a href="https://collegescorecard.ed.gov/data/" target="_blank" rel="external">这个数据集</a>，它包含了美国大学的招生条件，毕业率，和毕业生未来收入的数据。这就是一个可以用来讲故事的很好的数据集。然而，如果你深入地去想，你就会发现这里面没有足够的细节来建立一个好项目。举例说，你可以告诉别人如果他们去某些（好）大学，他们未来的潜在收入就会更高，但是这只需要一个很快的查找比较就可以完成，而没有足够的空间去展示你的技术竞争力。你也可以发现如果大学有更高的入学条件，它们的毕业生就更有可能获得高薪，但这些就更偏向于讲故事，而非运营技术了。</p>
<p>当你有GB以上的数据量时，或者当你想要预测一些数据细节，需要对数据集进行一些算法运算时，内存和性能限制就会逐渐凸现出来。</p>
<p>一个好的运营数据集可以让你建立一系列的脚本，这些脚本可以帮助你给数据做变形，从而可以回答一些动态的问题。股票价格就是一个很好的数据集。你可以根据这些数据在第二天预测当天的股价走势，并且在股市关闭的时候把新数据提供给算法。这可以帮助你执行交易，甚至可以帮你获取利润。这就不是在讲故事了 – 这就是直接在产生价值。</p>
<p>一些能够找到好数据集的地方：</p>
<ul>
<li><a href="https://reddit.com/r/datasets" target="_blank" rel="external">/r/datasets</a> – 一个有着上百有趣的数据集的subreddit</li>
<li><a href="https://cloud.google.com/bigquery/public-data/#usa-names" target="_blank" rel="external">Google Public Datasets</a> – 一些在Google BigQuery上的公共数据集</li>
<li><a href="https://github.com/caesar0301/awesome-public-datasets" target="_blank" rel="external">Awesome datasets</a> – 一个托管在Github上的数据集清单</li>
</ul>
<p>当你在看这些数据集的时候，想一想一个人如果有这些数据集，可能会回答些什么问题，然后再想想这些问题是否是一次性的（“S&amp;P 500和房价的相关性是怎样的？”），或是不间断的（“你能预测股票价格吗？”）。这里的关键在于找到那些不间断的问题，这些问题会需要同样的代码在不同的时间用不同的数据去运行。</p>
<p>在这篇文章里面，我们选择<a href="http://www.fanniemae.com/portal/funding-the-market/data/loan-performance-data.html" target="_blank" rel="external">Fannie Mae贷款数据</a>。Fannie Mae是一个由美国政府资助的从贷方手里购买房贷的企业。它购买房贷之后，会把这些房贷打包到一些由房贷支撑的证券里，再卖出去。这样就帮助了贷方可以贷出更多的房贷，并给市场创造了更大的流动性。这，从理论上说，就会产生更多的房屋业主，进而产生更好的房贷政策。然而从借方的角度来看，事情大致并没有什么不同。</p>
<p>Fannie Mae 开放了两种数据 – 它得到的房贷数据，和这些房贷一段时间后的表现情况数据。在最理想的情况下，一个人从贷方贷了款，然后一直还钱，知道贷款还清。然而，当借方有几次没有还款，就可能会导致他失去抵押品赎回权。这时，银行就会获得房屋的所有权，因为房贷不能还清。Fannie Mae记录了哪些房贷没有还，哪些房贷需要取消借方的抵押品赎回权。这个数据一个季度发布一次，最新的数据会是去年的。在撰写本文档 时候，最近的数据集是<code>2015</code>的第一个季度。</p>
<p>当Fannie Mae得到房贷时发布的收购信息，涵盖了许多关于借方的信息，包括信用记录，和关于借方的房贷和房屋的信息。在房贷借出的每个季度发布的房贷表现信息里，涵盖了借方的支付信息，和抵押权的状态。一个房贷的表现信息里可能有很多行。你可以这么想这个事，收购信息告诉你Fannie Mae现在控制了房贷，表现信息则包括了一系列房贷的状况更新。一种状态可能会告诉我们这笔贷款在今年的某个季度借方抵押权被取消了。</p>
<p><img src="https://www.dataquest.io/blog/images/end_to_end/foreclosure.jpg" alt=""><br><em>一个借方失去了抵押品赎回权（止赎）的房子正在被卖</em></p>
<p>#选一个角度<br>有了Fannie Mae数据集之后，我们可以从几个角度出发。我们可以：</p>
<ul>
<li>尝试预测一个止赎了的房屋的售价</li>
<li>预测一个借方的还款历史</li>
<li>收购时，计算出一个房贷评分</li>
</ul>
<p>重要的事是要坚持一个单一的角度。想专注于太多事情会很难做成一个优秀的项目。也很重要的是选一个有足够细节的角度。这里是一些没有多少细节的角度：</p>
<ul>
<li>找到哪间银行卖给Fannie Mae最多止赎的房贷</li>
<li>找到借方信用记录的趋势</li>
<li>探索哪些房屋类型最经常止赎</li>
<li>探索房贷金额和止赎售价的关系</li>
</ul>
<p>上述的这些角度都很有趣，而且如果我们关注讲故事的话也会很棒，但对于一个运营性的项目来说就没那么好了。</p>
<p>有了Fannie Mae数据集，我们会尝试预测一个房贷是否会被止赎 – 仅仅使用收购房贷时的数据。实际来说，我们会为每一份房贷创建一个“分数”，这个分数会告诉Fannie Mae是否应该购买这份房贷。这会给我们一个良好的基础，也是一个很棒的作品。</p>
<p>#理解数据</p>
<p>让我们很快地看一看原始的数据文件。这里是2012年第一季度的收购数据的前几行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">100000853384|R|OTHER|4.625|280000|360|02/2012|04/2012|31|31|1|23|801|N|C|SF|1|I|CA|945||FRM|</div><div class="line">100003735682|R|SUNTRUST MORTGAGE INC.|3.99|466000|360|01/2012|03/2012|80|80|2|30|794|N|P|SF|1|P|MD|208||FRM|788</div><div class="line">100006367485|C|PHH MORTGAGE CORPORATION|4|229000|360|02/2012|04/2012|67|67|2|36|802|N|R|SF|1|P|CA|959||FRM|794</div></pre></td></tr></table></figure></p>
<p>这里是2012年第一季度的表现数据的前几行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">100000853384|03/01/2012|OTHER|4.625||0|360|359|03/2042|41860|0|N||||||||||||||||</div><div class="line">100000853384|04/01/2012||4.625||1|359|358|03/2042|41860|0|N||||||||||||||||</div><div class="line">100000853384|05/01/2012||4.625||2|358|357|03/2042|41860|0|N||||||||||||||||</div></pre></td></tr></table></figure>
<p>在讲代码之前，花点时间去理解数据是很有用的。在运营型项目里这点更重要 – 因为我们不会互动式地去探索数据，找寻某些细节变得更难，除非我们一开始就找到它们。这种情况下，第一步就是去Fannie Mae网站上读一读它的材料：</p>
<ul>
<li><a href="http://www.fanniemae.com/portal/funding-the-market/data/loan-performance-data.html" target="_blank" rel="external">简介</a></li>
<li><a href="https://loanperformancedata.fanniemae.com/lppub-docs/lppub_glossary.pdf" target="_blank" rel="external">词汇表</a></li>
<li><a href="https://loanperformancedata.fanniemae.com/lppub-docs/lppub_faq.pdf" target="_blank" rel="external">常见问题</a></li>
<li><a href="https://loanperformancedata.fanniemae.com/lppub-docs/lppub_file_layout.pdf" target="_blank" rel="external">收购和表现文件里的列</a></li>
<li><a href="https://loanperformancedata.fanniemae.com/lppub-docs/acquisition-sample-file.txt" target="_blank" rel="external">收购数据样本文件</a></li>
<li><a href="https://loanperformancedata.fanniemae.com/lppub-docs/performance-sample-file.txt" target="_blank" rel="external">表现数据样本文件</a></li>
</ul>
<p>在阅读了材料之后，我们知道了一些可以帮助我们的关键信息：</p>
<ul>
<li>每个季度都有一个收购文件和表现文件，从<code>2000</code>年到现在。数据距离现在有1年的间隔，所以最近的数据是2015年</li>
<li>这些文件是文档形式，用<code>|</code>作为分隔符</li>
<li>这些文件没有头文档，但是我们有所有列名称的一个列表</li>
<li>全部加起来，这些文件包括了<code>2.2</code>千万的房贷</li>
<li>因为表现文件涵盖了之前的房贷信息，所以早些时候的房贷会有更多的表现数据（举个例子，<code>2014</code>年收购的房贷不会有太多表现信息）</li>
</ul>
<p>这一点点的信息会帮我们在结构化项目和处理数据时节省一大笔时间。</p>
<p>#结构化项目</p>
<p>在我们开始下载和探索数据之前，我们如何把数据结构化是非常重要的。在创建项目的时候，我们主要的目标是：</p>
<ul>
<li>创造一个可行的解决方法</li>
<li>拥有一个运行快且消耗最少资源的解决方案</li>
<li>让他人可以很容易地扩展我们的工作</li>
<li>让他人可以容易地理解我们的代码</li>
<li>写的代码越少越好</li>
</ul>
<p>为了达到这些目标，我们也需要结构化我们的数据。一个有良好结构的项目跟从以下的规范：</p>
<ul>
<li>数据文件和源代码分开放置</li>
<li>原始数据和生成的数据分开放置</li>
<li>有一个<code>README.md</code>文件，可以帮助人们安装并使用这个项目</li>
<li>有一个<code>requirements.txt</code>文件，该文件包括这个项目所需的所有模块</li>
<li>有一个<code>settings.py</code>文件，包括所有其他文件里面的设置<ul>
<li>举例来说，如果你有很多Python脚本都读取同一个文件，就不如让它们都导入<code>settings</code>并从这一个地方来得到文件</li>
</ul>
</li>
<li>有一个<code>.gitignore</code>文件，来防止一些特别大的或者私密的文件被commit</li>
<li>把我们的任务分成几步，并分别放在几个可以单独执行的文件里<ul>
<li>举例来说， 我们可能用一个文件读取数据，一个文件建立特征，一个文件执行预测</li>
</ul>
</li>
<li>储存中间值。举例来说，一个脚本可能会输出一个文件，这个文件又会被另外一个脚本读取<ul>
<li>这就使得我们可以在数据处理的流程中做一些改动，而又不需要重新计算所有的东西</li>
</ul>
</li>
</ul>
<p>一会，我们的文件就会呈现以下结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">loan-prediction</div><div class="line">├── data</div><div class="line">├── processed</div><div class="line">├── .gitignore</div><div class="line">├── README.md</div><div class="line">├── requirements.txt</div><div class="line">├── settings.py</div></pre></td></tr></table></figure></p>
<p>#创建初始文件</p>
<p>在开始时，我们要创建一个<code>loan-prediction</code>文件夹。在这个文件夹里，我们需要创建一个<code>data</code>文件夹和一个<code>processed</code>文件夹。第一个用来储存我们的原始数据，第二个用来储存所有中间值。</p>
<p>接着，我们创建一个<code>.gitignore</code>文件。一个<code>.gitignore</code>文件会确保一些文件会被git忽略，并不会被push到Github上。一个这类文件很好的例子就是OSX在每个文件夹里创建的<code>.DS_Store</code>文件。要入门<code>.gitignore</code>文件，可以参考<a href="https://github.com/github/gitignore/blob/master/Python.gitignore" target="_blank" rel="external">这里</a>。我们也想忽略一些体积太大的文件，而且Fannie Mae的条款并不允许我们二次发布这些文件，所以我们应该在<code>.gitignore</code>文件最后加上这两行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">data</div><div class="line">processed</div></pre></td></tr></table></figure>
<p><a href="https://github.com/dataquestio/loan-prediction/blob/master/.gitignore" target="_blank" rel="external">这里</a>是本项目的<code>.gitignore</code>文件。</p>
<p>接着，我们需要创建<code>README.md</code>，这会帮助人们理解这个项目。<code>.md</code>代表这个文件是markdown格式。Markdown能让你直接用文字书写，但是如果你想要的话，也可以调用一些好看的排版格式。<a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet" target="_blank" rel="external">这里</a>是一个markdown的指南。如果你在Github上上传了一个叫<code>README.md</code>的文件，Github就会自动处理这个markdown,然后把它作为主页展示给浏览者。<a href="https://github.com/dataquestio/loan-prediction" target="_blank" rel="external">这</a>是一个例子。</p>
<p>暂时来说，我们只需要把一段简短的描述放在<code>README.md</code>里面：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Loan Prediction</div><div class="line">-----------------------</div><div class="line"></div><div class="line">Predict whether or not loans acquired by Fannie Mae will go into foreclosure.  Fannie Mae acquires loans from other lenders as a way of inducing them to lend more.  Fannie Mae releases data on the loans it has acquired and their performance afterwards [here](http://www.fanniemae.com/portal/funding-the-market/data/loan-performance-data.html).</div></pre></td></tr></table></figure>
<p>现在我们创建<code>requirements.txt</code>文件。这会帮助其他人安装我们的项目。我们还不知道我们具体需要哪些库，但这是一个好的起点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">pandas</div><div class="line">matplotlib</div><div class="line">scikit-learn</div><div class="line">numpy</div><div class="line">ipython</div><div class="line">scipy</div></pre></td></tr></table></figure>
<p>以上是用Python作数据分析的最常用的几个库，我们也可以假设我们在之后会用到它们。<a href="https://github.com/dataquestio/loan-prediction/blob/master/requirements.txt" target="_blank" rel="external">这是</a>本次项目的requirements文件。</p>
<p>在创建<code>requirements.txt</code>之后，你应该安装这些模块。在本文中我们会使用<code>Python 3</code>。如果你还没有安装Python，你应该尝试使用<a href="https://www.continuum.io/downloads" target="_blank" rel="external">Anaconda</a>，这是一个可以安装上述所有模块的Python安装器。</p>
<p>最后，我们可以暂时创建一个空白的<code>settings.py</code>文件，因为我们还没有为项目设置任何东西。</p>
<p>#获得数据</p>
<p>一旦我们有了整个项目的框架，我们就可以开始获取原始数据了。</p>
<p>Fannie Mae 对数据下载有一些限制，所以你得先注册一个账号。下载页面在<a href="https://loanperformancedata.fanniemae.com/lppub/index.html" target="_blank" rel="external">这里</a>。注册完账户后，你就可以想下载多少贷款数据就下载多少了。文件是zip格式，解压之后也挺大的。</p>
<p>为了这篇文章，我们会把<code>Q1 2012</code>至<code>Q1 2015</code>之间的所有数据都下载下来。之后我们需要解压文件。解压之后，删除原始的<code>.zip</code>文件。最后，<code>loan-prediction</code>文件夹的会呈现以下结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">loan-prediction</div><div class="line">├── data</div><div class="line">│   ├── Acquisition_2012Q1.txt</div><div class="line">│   ├── Acquisition_2012Q2.txt</div><div class="line">│   ├── Performance_2012Q1.txt</div><div class="line">│   ├── Performance_2012Q2.txt</div><div class="line">│   └── ...</div><div class="line">├── processed</div><div class="line">├── .gitignore</div><div class="line">├── README.md</div><div class="line">├── requirements.txt</div><div class="line">├── settings.py</div></pre></td></tr></table></figure>
<p>下载完数据之后，你可以用<code>head</code>和<code>tail</code>的shell命令去观察文件里面的前几行和后几行。你有看到一些我们不需要的列吗？在做这件事情的时候可以参考一下<a href="https://loanperformancedata.fanniemae.com/lppub-docs/lppub_file_layout.pdf" target="_blank" rel="external">pdf列名称</a></p>
<p>#读取数据</p>
<p>现在有两个问题，使得我们直接利用现在的数据：</p>
<ul>
<li>收购和表现数据集被分散在了许多文件里</li>
<li>所有文件都缺少头文档</li>
</ul>
<p>在我们处理这些数据之前，我们需要把集中所有的收购数据到一个文件，和集中所有的表现数据到一个文件。每个文件只需要包含我们关心的列的数据，和正常的头文档。这里的一个问题是表现数据特别大，所以可能的话我们得删减一些列。</p>
<p>第一步是在<code>settings.py</code>里面增添一些变量，这些变量会包含到原始数据和中间数据的路径。我们也会加上一点在之后会有用的数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">DATA_DIR = &quot;data&quot;</div><div class="line">PROCESSED_DIR = &quot;processed&quot;</div><div class="line">MINIMUM_TRACKING_QUARTERS = 4</div><div class="line">TARGET = &quot;foreclosure_status&quot;</div><div class="line">NON_PREDICTORS = [TARGET, &quot;id&quot;]</div><div class="line">CV_FOLDS = 3</div></pre></td></tr></table></figure>
<p>把路径放在<code>settings.py</code>里面会使得它们统一在一个地方，使得今后改动它们变得简单。当许多文件都用了同一些变量的时候，把它们放在一起会比分别在每个文件里做改动要简单得多。<a href="https://github.com/dataquestio/loan-prediction/blob/master/settings.py" target="_blank" rel="external">这里</a>是该项目的<code>settings.py</code>文件。</p>
<p>第二步是创建一个叫做<code>assemble.py</code>的文件，这个文件会把所有东西组合成<code>2</code>个文件。当我们运行<code>python assemble.py</code>的时候，我们会在<code>processed</code>文件夹里面得到<code>2</code>个数据文件。</p>
<p>我们一开始先给<code>assemble.py</code>写代码。要开始，我们得给每个文件定义头文档，所以我们需要看一看<a href="https://loanperformancedata.fanniemae.com/lppub-docs/lppub_file_layout.pdf" target="_blank" rel="external">列名称的pdf文档</a>然后给每个收购和表现文件建立一系列列表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line">HEADERS = &#123;</div><div class="line">    &quot;Acquisition&quot;: [</div><div class="line">        &quot;id&quot;,</div><div class="line">        &quot;channel&quot;,</div><div class="line">        &quot;seller&quot;,</div><div class="line">        &quot;interest_rate&quot;,</div><div class="line">        &quot;balance&quot;,</div><div class="line">        &quot;loan_term&quot;,</div><div class="line">        &quot;origination_date&quot;,</div><div class="line">        &quot;first_payment_date&quot;,</div><div class="line">        &quot;ltv&quot;,</div><div class="line">        &quot;cltv&quot;,</div><div class="line">        &quot;borrower_count&quot;,</div><div class="line">        &quot;dti&quot;,</div><div class="line">        &quot;borrower_credit_score&quot;,</div><div class="line">        &quot;first_time_homebuyer&quot;,</div><div class="line">        &quot;loan_purpose&quot;,</div><div class="line">        &quot;property_type&quot;,</div><div class="line">        &quot;unit_count&quot;,</div><div class="line">        &quot;occupancy_status&quot;,</div><div class="line">        &quot;property_state&quot;,</div><div class="line">        &quot;zip&quot;,</div><div class="line">        &quot;insurance_percentage&quot;,</div><div class="line">        &quot;product_type&quot;,</div><div class="line">        &quot;co_borrower_credit_score&quot;</div><div class="line">    ],</div><div class="line">    &quot;Performance&quot;: [</div><div class="line">        &quot;id&quot;,</div><div class="line">        &quot;reporting_period&quot;,</div><div class="line">        &quot;servicer_name&quot;,</div><div class="line">        &quot;interest_rate&quot;,</div><div class="line">        &quot;balance&quot;,</div><div class="line">        &quot;loan_age&quot;,</div><div class="line">        &quot;months_to_maturity&quot;,</div><div class="line">        &quot;maturity_date&quot;,</div><div class="line">        &quot;msa&quot;,</div><div class="line">        &quot;delinquency_status&quot;,</div><div class="line">        &quot;modification_flag&quot;,</div><div class="line">        &quot;zero_balance_code&quot;,</div><div class="line">        &quot;zero_balance_date&quot;,</div><div class="line">        &quot;last_paid_installment_date&quot;,</div><div class="line">        &quot;foreclosure_date&quot;,</div><div class="line">        &quot;disposition_date&quot;,</div><div class="line">        &quot;foreclosure_costs&quot;,</div><div class="line">        &quot;property_repair_costs&quot;,</div><div class="line">        &quot;recovery_costs&quot;,</div><div class="line">        &quot;misc_costs&quot;,</div><div class="line">        &quot;tax_costs&quot;,</div><div class="line">        &quot;sale_proceeds&quot;,</div><div class="line">        &quot;credit_enhancement_proceeds&quot;,</div><div class="line">        &quot;repurchase_proceeds&quot;,</div><div class="line">        &quot;other_foreclosure_proceeds&quot;,</div><div class="line">        &quot;non_interest_bearing_balance&quot;,</div><div class="line">        &quot;principal_forgiveness_balance&quot;</div><div class="line">    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下一步是定义我们需要保留哪些列。因为我们最终持续关心的房贷只是关于它有没有被止赎，所以我们可以从表现数据里面丢弃很多列（不影响是否止赎的数据）。但是我们需要保留所有收购数据，因为我们想要最大化关于被收购的房贷的信息（因为最终我们是在房贷被收购的时候预测它是否会被止赎）。丢弃一些列可以让我们省下一些磁盘空间和内存，同时也会加速代码的运行速度。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">SELECT = &#123;</div><div class="line">    &quot;Acquisition&quot;: HEADERS[&quot;Acquisition&quot;],</div><div class="line">    &quot;Performance&quot;: [</div><div class="line">        &quot;id&quot;,</div><div class="line">        &quot;foreclosure_date&quot;</div><div class="line">    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>接下来，我们要写一个函数来连接所有的数据集。下面的代码会：</p>
<ul>
<li>导入一些需要的库，包括<code>settings</code></li>
<li>定义一个函数<code>concatenate</code>，它可以：<ul>
<li>拿到<code>data</code>目录里面所有文件的名字</li>
<li>遍历每个文件<ul>
<li>如果文件的格式不对（并不是以我们想要的前缀开始），我们就忽略它</li>
<li>用Pandas的<a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" target="_blank" rel="external">read_csv</a>函数，用合适的设置，把文件读取到一个<a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html" target="_blank" rel="external">DataFrame</a>里<ul>
<li>把分隔符设置为<code>|</code>使得数据可以正确地读取</li>
<li>数据现在没有头文档，所以把<code>header</code>设置成<code>None</code></li>
<li>把<code>HEADERS</code>字典里的值设置给列的名称，这些会成为我们DataFrame里面的列名称</li>
<li>只把我们加在<code>SELECT</code>里面的列从DataFrame里面选出来</li>
</ul>
</li>
<li>把所有的DataFrame连接在一起</li>
<li>把连接好的DataFrame输出成一个文件</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line">import settings</div><div class="line">import pandas as pd</div><div class="line"></div><div class="line">def concatenate(prefix=&quot;Acquisition&quot;):</div><div class="line">    files = os.listdir(settings.DATA_DIR)</div><div class="line">    full = []</div><div class="line">    for f in files:</div><div class="line">        if not f.startswith(prefix):</div><div class="line">            continue</div><div class="line"></div><div class="line">        data = pd.read_csv(os.path.join(settings.DATA_DIR, f), sep=&quot;|&quot;, header=None, names=HEADERS[prefix], index_col=False)</div><div class="line">        data = data[SELECT[prefix]]</div><div class="line">        full.append(data)</div><div class="line"></div><div class="line">    full = pd.concat(full, axis=0)</div><div class="line"></div><div class="line">    full.to_csv(os.path.join(settings.PROCESSED_DIR, &quot;&#123;&#125;.txt&quot;.format(prefix)), sep=&quot;|&quot;, header=SELECT[prefix], index=False)</div></pre></td></tr></table></figure>
<p>我们可以用参数<code>Acquisition</code>和<code>Performance</code>调用两次上面的函数，来把所有的收购和表现文件连接在一起。下面的代码会：</p>
<ul>
<li>只当脚本是在命令性用<code>python assemble.py</code>执行时运行</li>
<li>连接所有文件，并输出成两个文件：<ul>
<li><code>processed/Acquisition.txt</code></li>
<li><code>processed/Performance.txt</code></li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line">    concatenate(&quot;Acquisition&quot;)</div><div class="line">    concatenate(&quot;Performance&quot;)</div></pre></td></tr></table></figure>
<p>我们现在有了一个良好划分的<code>assemble.py</code>文件，它既容易运行，又易扩展。像这样把大问题划分成小问题，我们将项目变得更简单。我们把不同文件分离开，定义它们之间的数据结构，而不是用一个脚本做所有的事情。当你在做一个大项目的时候，这样做通常很好，因为这样你就可以更改一些文件而不会产生不可预期的结果。</p>
<p>一旦我们完成了<code>assemble.py</code>的脚本，我们就可以来运行它。你可以在<a href="https://github.com/dataquestio/loan-prediction/blob/master/assemble.py" target="_blank" rel="external">这里</a>找到它。</p>
<p>这就会在<code>processed</code>目录里面输出两个文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">loan-prediction</div><div class="line">├── data</div><div class="line">│   ├── Acquisition_2012Q1.txt</div><div class="line">│   ├── Acquisition_2012Q2.txt</div><div class="line">│   ├── Performance_2012Q1.txt</div><div class="line">│   ├── Performance_2012Q2.txt</div><div class="line">│   └── ...</div><div class="line">├── processed</div><div class="line">│   ├── Acquisition.txt</div><div class="line">│   ├── Performance.txt</div><div class="line">├── .gitignore</div><div class="line">├── assemble.py</div><div class="line">├── README.md</div><div class="line">├── requirements.txt</div><div class="line">├── settings.py</div></pre></td></tr></table></figure>
<p>#在表现数据里进行计算</p>
<p>我们的下一步就是从<code>processed/Performance.txt</code>里面计算一些值。我们想做的就是预测一间房产以后会不会被止赎。为了弄明白这一点，我们只需要看看表现数据里面的房贷是否有一个<code>foreclosure_date</code>。如果<code>foreclosure_date</code>是<code>None</code>，那么这间房产就没有被止赎。我们也需要规避那些在表现数据里没有多少历史数据的房贷，要做到这一点，我们通过计算它们在表现数据里面累计有多少行。这就可以帮我们过滤掉那些没多少历史数据的房贷。</p>
<p>我们可以用下面的方法来思考收购数据和表现数据的关系：</p>
<p><img src="https://www.dropbox.com/s/f0ld1ztm7w5lim6/Screenshot%202016-09-29%2021.56.18.png?raw=1" alt=""></p>
<p>可以看到的是，在收购数据里每一行都在表现数据里对应了多行。在表现数据里面，当止赎发生的时候，当季度的<code>foreclosure_date</code>就会出现，在这之前都应该是空白的。一些贷款从未被止赎，所以与之相关的表现数据里的<code>foreclosure_date</code>都是空白的。</p>
<p>我们需要计算<code>foreclorsure_status</code>，这是一个布尔值，代表一个贷款<code>id</code>是否有被止赎过。我们也要计算<code>performance_count</code>，也就是每个<code>id</code>在表现数据里有多少行。</p>
<p>有几种方法可以计算我们想要的<code>performance_count</code>：</p>
<pre><code>- 我们可以读取所有的表现数据，然后用Pandas的[groupby](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)方法来搞清楚和每个贷款`id`相关联的行数，同时也可以搞清楚这个`id`的`foreclosure_date`有没有不是`None`过。
    - 这样做的好处是实现的语法很简单
    - 这样做的坏处是读取`129236094`行数据会花很多内存，也会极其得慢
- 我们可以读取所有的表现数据，然后用[apply](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html)在收购数据DataFrame身上，从而找到每个`id`的计数
    - 好处是概念上很简单
    - 坏处仍然是读取`129236094`行数据会花很多内存，也会极其得慢
- 我们可以表现数据里的每一行，然后保存一个单独的包含计数的字典
    - 好处是我们不需要把所有数据一起读取进内存，所以这样做会很快，也会优化内存
    - 坏处是我们得花长一点时间来理清概念和实现，而且我们需要手工地解析每一行
</code></pre><p>把所有数据一并加载会花很多内存，所以我们采用第三种方法。我们所要的就是遍历表现数据里面的每一行，并且保存一个包含每个<code>id</code>的计数字典。在字典里面，我们记录下表现数据里面每个<code>id</code>出现了多少次，并且是否<code>foreclosure_date</code>是否为非<code>None</code>过。这就给了我们<code>foreclosure_date</code>和<code>performance_count</code>。</p>
<p>我们要新建一个文件<code>annotate.py</code>，并加进我们用来计算的代码。在下面的代码里面，我们会：</p>
<pre><code>- 导入需要的库
- 定义一个叫做`count_performance_rows`的函数
    - 打开`precessed/Performance.txt`。这不会把文件读取进内存，而仅仅是打开一个文件管理者，它可以帮我们一行一行地读取文件内容
    - 遍历文件里的每一行
        - 遇见分隔符`|`就分割字符串
        - 检查`loan_id`是否在`counts`字典里
            - 如果不在，把它加入`counts`
        - 给`load_id`对应的`performance_count`加1
        - 如果`date`不是`None`，那么我们就知道这笔贷款止赎了，所以设置`foreclosure_status`
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line">import settings</div><div class="line">import pandas as pd</div><div class="line"></div><div class="line">def count_performance_rows():</div><div class="line">    counts = &#123;&#125;</div><div class="line">    with open(os.path.join(settings.PROCESSED_DIR, &quot;Performance.txt&quot;), &apos;r&apos;) as f:</div><div class="line">        for i, line in enumerate(f):</div><div class="line">            if i == 0:</div><div class="line">                # Skip header row</div><div class="line">                continue</div><div class="line">            loan_id, date = line.split(&quot;|&quot;)</div><div class="line">            loan_id = int(loan_id)</div><div class="line">            if loan_id not in counts:</div><div class="line">                counts[loan_id] = &#123;</div><div class="line">                    &quot;foreclosure_status&quot;: False,</div><div class="line">                    &quot;performance_count&quot;: 0</div><div class="line">                &#125;</div><div class="line">            counts[loan_id][&quot;performance_count&quot;] += 1</div><div class="line">            if len(date.strip()) &gt; 0:</div><div class="line">                counts[loan_id][&quot;foreclosure_status&quot;] = True</div><div class="line">    return counts</div></pre></td></tr></table></figure>
<p>#得到计算结果</p>
<p>一旦我们创建了我们的counts字典，我们就可以用一个函数抽取出和传入的<code>load_id</code>和<code>key</code>相应的值了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">def get_performance_summary_value(loan_id, key, counts):</div><div class="line">    value = counts.get(loan_id, &#123;</div><div class="line">        &quot;foreclosure_status&quot;: False,</div><div class="line">        &quot;performance_count&quot;: 0</div><div class="line">    &#125;)</div><div class="line">    return value[key]</div></pre></td></tr></table></figure>
<p>上面的这个函数会从<code>counts</code>字典里返回适当的值，并且会让我们可以赋予收购数据里每一行一个<code>foreclosure_status</code>和<code>performance_count</code>值。字典里的<a href="https://docs.python.org/3/library/stdtypes.html#dict.get" target="_blank" rel="external">get</a>方法在没有找到key的情况下就会返回一个默认值，所以这就让我们可以区分是否找到了某个key。</p>
<p>#给数据做标记</p>
<p>我们已经给<code>annotate.py</code>加上一些函数了，现在我们就可以开始处理最有价值的部分了。我们需要把收购数据转换成一个机器学习算法可以使用的训练集。这就包含了以下几件事：</p>
<ul>
<li>把所有数据变成数字</li>
<li>补足空白的值</li>
<li>给每一行赋予一个<code>performance_count</code>和一个<code>foreclosure_status</code></li>
<li>删除那些没有表现历史数据的行（那些<code>performance_count</code>很低的行）</li>
</ul>
<p>我们有几列的数据都是文字，这在机器学习里没有什么用。然而它们其实是类别变量，比如说<code>R</code>,<code>S</code>这样的类别编号。我们分别赋予它们数字，从而把它们变成数字：</p>
<p><img src="https://www.dropbox.com/s/cy5mueqz7vgxxa2/Screenshot%202016-09-29%2022.40.02.png?raw=1" alt=""></p>
<p>这样转化了它们之后就能把它们在机器学习上用到。</p>
<p>一些列也包含了时间（<code>first_payment_date</code>和<code>origination_date</code>）。我们可以分别把它们分割成两列：</p>
<p><img src="https://www.dropbox.com/s/fumpjfvbim1ot9d/Screenshot%202016-09-29%2022.41.22.png?raw=1" alt=""></p>
<p>下面的代码里，我们会转换收购数据。我们会定义一个函数，这个函数会：</p>
<ul>
<li>通过从<code>counts</code>字典里获取数据，在<code>acquisition</code>里建立一个<code>foreclosure_status</code>列</li>
<li>通过从<code>counts</code>字典里获取数据，在<code>acquisition</code>里建立一个<code>performance_count</code>列</li>
<li>把下面的列从文字转成数字：<ul>
<li><code>channel</code> </li>
<li><code>seller</code></li>
<li><code>first_time_homebuyer</code></li>
<li><code>loan_purpose</code></li>
<li><code>property_type</code></li>
<li><code>occupancy_status</code></li>
<li><code>property_state</code></li>
<li><code>product_type</code></li>
</ul>
</li>
<li>分别把<code>first_payment_date</code>和<code>origination_date</code>转换成两列：<ul>
<li>遇见<code>/</code>就分割</li>
<li>把第一部分赋予<code>month</code>列</li>
<li>把第二部分赋予<code>year</code>列</li>
<li>删除原本列</li>
<li>最后，我们就会有<code>first_payment_month</code>, <code>first_payment_year</code>, <code>origination_month</code>和<code>origination_year</code></li>
</ul>
</li>
<li>在<code>acquisition</code>里的所有缺失值都替换成<code>-1</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">def annotate(acquisition, counts):</div><div class="line">    acquisition[&quot;foreclosure_status&quot;] = acquisition[&quot;id&quot;].apply(lambda x: get_performance_summary_value(x, &quot;foreclosure_status&quot;, counts))</div><div class="line">    acquisition[&quot;performance_count&quot;] = acquisition[&quot;id&quot;].apply(lambda x: get_performance_summary_value(x, &quot;performance_count&quot;, counts))</div><div class="line">    for column in [</div><div class="line">        &quot;channel&quot;,</div><div class="line">        &quot;seller&quot;,</div><div class="line">        &quot;first_time_homebuyer&quot;,</div><div class="line">        &quot;loan_purpose&quot;,</div><div class="line">        &quot;property_type&quot;,</div><div class="line">        &quot;occupancy_status&quot;,</div><div class="line">        &quot;property_state&quot;,</div><div class="line">        &quot;product_type&quot;</div><div class="line">    ]:</div><div class="line">        acquisition[column] = acquisition[column].astype(&apos;category&apos;).cat.codes</div><div class="line"></div><div class="line">    for start in [&quot;first_payment&quot;, &quot;origination&quot;]:</div><div class="line">        column = &quot;&#123;&#125;_date&quot;.format(start)</div><div class="line">        acquisition[&quot;&#123;&#125;_year&quot;.format(start)] = pd.to_numeric(acquisition[column].str.split(&apos;/&apos;).str.get(1))</div><div class="line">        acquisition[&quot;&#123;&#125;_month&quot;.format(start)] = pd.to_numeric(acquisition[column].str.split(&apos;/&apos;).str.get(0))</div><div class="line">        del acquisition[column]</div><div class="line"></div><div class="line">    acquisition = acquisition.fillna(-1)</div><div class="line">    acquisition = acquisition[acquisition[&quot;performance_count&quot;] &gt; settings.MINIMUM_TRACKING_QUARTERS]</div><div class="line">    return acquisition</div></pre></td></tr></table></figure>
<p>#连接所有的结果</p>
<p>我们就快准备好把所有结果联系起来了，在这之前我们只是要再加一些代码到<code>annotate.py</code>里。在下面的代码中，我们：</p>
<ul>
<li>定义一个函数来读取收购数据</li>
<li>顶一个函数把处理过的数据写入<code>processed/train.csv</code></li>
<li>如果文件是从命令行传入的，比如<code>python annotate.py</code>，就:<ul>
<li>读取收购数据</li>
<li>计算表现数据的累计数目，并赋予<code>counts</code></li>
<li>给<code>acquisition</code>DataFrame做标记</li>
<li>把<code>acquisition</code>DataFrame写入<code>train.csv</code></li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">def read():</div><div class="line">    acquisition = pd.read_csv(os.path.join(settings.PROCESSED_DIR, &quot;Acquisition.txt&quot;), sep=&quot;|&quot;)</div><div class="line">    return acquisition</div><div class="line">    </div><div class="line">def write(acquisition):</div><div class="line">    acquisition.to_csv(os.path.join(settings.PROCESSED_DIR, &quot;train.csv&quot;), index=False)</div><div class="line"></div><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line">    acquisition = read()</div><div class="line">    counts = count_performance_rows()</div><div class="line">    acquisition = annotate(acquisition, counts)</div><div class="line">    write(acquisition)</div></pre></td></tr></table></figure>
<p>写好文件后，记得用<code>python annotate.py</code>来运行它，得到一个<code>train.csv</code>文件。完整的<code>annotate.py</code>文件在<a href="https://github.com/dataquestio/loan-prediction/blob/master/annotate.py" target="_blank" rel="external">这里</a></p>
<p>文件夹现在应该长这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">loan-prediction</div><div class="line">├── data</div><div class="line">│   ├── Acquisition_2012Q1.txt</div><div class="line">│   ├── Acquisition_2012Q2.txt</div><div class="line">│   ├── Performance_2012Q1.txt</div><div class="line">│   ├── Performance_2012Q2.txt</div><div class="line">│   └── ...</div><div class="line">├── processed</div><div class="line">│   ├── Acquisition.txt</div><div class="line">│   ├── Performance.txt</div><div class="line">│   ├── train.csv</div><div class="line">├── .gitignore</div><div class="line">├── annotate.py</div><div class="line">├── assemble.py</div><div class="line">├── README.md</div><div class="line">├── requirements.txt</div><div class="line">├── settings.py</div></pre></td></tr></table></figure>
<h1 id="找到误差衡量方法"><a href="#找到误差衡量方法" class="headerlink" title="找到误差衡量方法"></a>找到误差衡量方法</h1><p>我们已经完成如何生成数据了，现在我们只需要完成最后一步，生成预测。我们需要弄明白一个误差的衡量方法，以及我们如何衡量我们的数据。这里来说，没有被止赎的贷款比止赎的贷款多得多，所以典型的准确度不太有用。</p>
<p>如果我们看一看训练数据，并看一看<code>foreclosure_status</code>列的计数，我们会得到这些：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">import pandas as pd</div><div class="line">import settings</div><div class="line"></div><div class="line">train = pd.read_csv(os.path.join(settings.PROCESSED_DIR, &quot;train.csv&quot;))</div><div class="line">train[&quot;foreclosure_status&quot;].value_counts()</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">False    4635982</div><div class="line">True        1585</div><div class="line">Name: foreclosure_status, dtype: int64</div></pre></td></tr></table></figure>
<p>因为只有这么一点点贷款是止赎了，所以如果我们只看有多少百分比的标签被正确预测了，那我们就可以建立一个只预测<code>False</code>的模型，一样可以得到很高的准确度。所以我们会用一个把这种不平衡考虑进去，保证我们准确预测止赎的误差测量法。我们不像要太多假的正预测，也就是我们预测一个贷款会止赎，但其实不会，或者太多的假的负样本，也就是我们预测一个贷款不会被止赎，但其实会。在这两者之间，假的负样本对Fannie Mae来说消耗更大，因为Fannie Mae就会买一些不能够弥补他们的投资的房贷了。</p>
<p>我们定义假的负样本率为我们预测不会止赎但其实会的预测数量，除以总的止赎贷款数量。这就是模型错过的止赎的百分比。下面是一个图表：</p>
<p><img src="https://www.dropbox.com/s/vauljb4xp2qnz7n/Screenshot%202016-09-29%2023.16.57.png?raw=1" alt=""></p>
<p>在上图表中，<code>1</code>个贷款被预测为非止赎，但它其实是。如果我们把它除以真的止赎的贷款数量,<code>2</code>，我们就得到的假的负样本率,<code>50%</code>。我们会用它作为我们的误差衡量，这样我们能够有效地评估我们模型的表现。</p>
<p>#为机器学习设置好分类器</p>
<p>我们会使用交叉验证来做预测。用交叉验证，我们会把数据分成<code>3</code>组，然后做以下的事：</p>
<ul>
<li>在<code>1</code>组和<code>2</code>组上训练，然后在<code>3</code>组上预测</li>
<li>在<code>1</code>组和<code>3</code>组上训练，然后在<code>2</code>组上预测</li>
<li>在<code>2</code>组和<code>3</code>组上训练，然后在<code>1</code>组上预测</li>
</ul>
<p>把它分成几组意味着我们不会用同样的数据来训练模型然后又用同样的数据来做预测。这就避免了过拟合。如果我们过拟合了，我们就会得到一个假的很低的假的负样本率，也就是说我们的模型很难在真实世界应用。</p>
<p><a href="http://scikit-learn.org/" target="_blank" rel="external">Scikit-learn</a>有一个叫做<a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_predict.html" target="_blank" rel="external">cross_val_predict</a>的函数，它让我们做交叉验证变得很容易。</p>
<p>我们还需要挑选一个算法来做预测。我们需要一个分类器来做<a href="https://en.wikipedia.org/wiki/Binary_classification" target="_blank" rel="external">二元分类</a>。因为目标变量，<code>foreclosure_status</code>只有两个值，<code>True</code>和<code>Flase</code></p>
<p>我们会使用<a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank" rel="external">logistic regression</a>。因为它在二元分类下表现很好 – 运行得极快,而且消耗很少内存.这是因为这个算法的工作方式 – 它比起建立一堆决策树,比如随机森林,或者做一些很昂贵的计算,比如支持向量机来说,需要少得多的步骤,只需要一些矩阵的操作而已.</p>
<p>我们可以用scikit-learn里自带的<a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" target="_blank" rel="external">logistic regression classifier</a>算法. 我们需要注意的唯一一件事就是每个类的weight. 如果我们给每个类同样的比重, 算法就会给每一行预测<code>False</code>, 因为它想要最小化误差. 然而,我们更关心止赎的贷款而不是不会止赎的贷款. 因此,我们给<a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" target="_blank" rel="external">Logistic Regression</a>传入<code>balanced</code>参数到<code>class_weight</code>关键词里, 从而得到一个考虑样本数量而给于平衡的比重的算法.这样就能确保算法不会对每一行都预测<code>False</code>, 而是在出现误差时对每个类都给予相等的惩罚.</p>
<p>#做预测</p>
<p>既然我们所有的前提都搞定了, 我们可以开始做预测了. 我们会创建一个新文件叫做<code>predict.py</code>, 它会使用我们之前创建的<code>train.csv</code>. 下面的代码会:</p>
<ul>
<li>导入需要的库</li>
<li>创建一个<code>cross_validate</code>函数,它会:<ul>
<li>用正确的关键词参数创建一个logitic regression分类器</li>
<li>创建我们想用来训练模型的数据列, 同时删除<code>id</code>he <code>foreclosure_statsu</code></li>
<li>在<code>train</code>DataFrame上运行交叉验证</li>
<li>返回预测</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line">import settings</div><div class="line">import pandas as pd</div><div class="line">from sklearn import cross_validation</div><div class="line">from sklearn.linear_model import LogisticRegression</div><div class="line">from sklearn import metrics</div><div class="line"></div><div class="line">def cross_validate(train):</div><div class="line">    clf = LogisticRegression(random_state=1, class_weight=&quot;balanced&quot;)</div><div class="line"></div><div class="line">    predictors = train.columns.tolist()</div><div class="line">    predictors = [p for p in predictors if p not in settings.NON_PREDICTORS]</div><div class="line"></div><div class="line">    predictions = cross_validation.cross_val_predict(clf, train[predictors], train[settings.TARGET], cv=settings.CV_FOLDS)</div><div class="line">    return predictions</div></pre></td></tr></table></figure>
<p>#预测误差</p>
<p>现在我们只需要写一些函数来计算误差.下面的代码会:</p>
<ul>
<li>创建一个函数<code>computer_error</code>, 它会:<ul>
<li>用scikit-learn计算一个简单准确度评分(符合真实<code>foreclosure_status</code>值的预测的百分比)</li>
</ul>
</li>
<li>创建一个函数<code>computer_false_negatives</code>, 它会:<ul>
<li>把目标和预测写进一个DataFrame</li>
<li>计算假的负样本率</li>
</ul>
</li>
<li>创建一个函数<code>computer_false_positives</code>, 它会:<ul>
<li>把目标和预测写进一个DataFrame</li>
<li>计算假的正样本率<ul>
<li>找到模型预测为止赎但并不是的贷款的数量</li>
<li>用这个数量除以不是止赎的贷款数量</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">def compute_error(target, predictions):</div><div class="line">    return metrics.accuracy_score(target, predictions)</div><div class="line"></div><div class="line">def compute_false_negatives(target, predictions):</div><div class="line">    df = pd.DataFrame(&#123;&quot;target&quot;: target, &quot;predictions&quot;: predictions&#125;)</div><div class="line">    return df[(df[&quot;target&quot;] == 1) &amp; (df[&quot;predictions&quot;] == 0)].shape[0] / (df[(df[&quot;target&quot;] == 1)].shape[0] + 1)</div><div class="line"></div><div class="line">def compute_false_positives(target, predictions):</div><div class="line">    df = pd.DataFrame(&#123;&quot;target&quot;: target, &quot;predictions&quot;: predictions&#125;)</div><div class="line">    return df[(df[&quot;target&quot;] == 0) &amp; (df[&quot;predictions&quot;] == 1)].shape[0] / (df[(df[&quot;target&quot;] == 0)].shape[0] + 1)</div></pre></td></tr></table></figure>
<p>#把所有东西连在一起</p>
<p>现在,我们已经把函数都放在了<code>predict.py</code>里面.下面的代码会:</p>
<ul>
<li>读取数据集</li>
<li>计算交叉验证预测</li>
<li>计算上述<code>3</code>个误差值</li>
<li>打印出误差值</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">def read():</div><div class="line">    train = pd.read_csv(os.path.join(settings.PROCESSED_DIR, &quot;train.csv&quot;))</div><div class="line">    return train</div><div class="line">    </div><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line">    train = read()</div><div class="line">    predictions = cross_validate(train)</div><div class="line">    error = compute_error(train[settings.TARGET], predictions)</div><div class="line">    fn = compute_false_negatives(train[settings.TARGET], predictions)</div><div class="line">    fp = compute_false_positives(train[settings.TARGET], predictions)</div><div class="line">    print(&quot;Accuracy Score: &#123;&#125;&quot;.format(error))</div><div class="line">    print(&quot;False Negatives: &#123;&#125;&quot;.format(fn))</div><div class="line">    print(&quot;False Positives: &#123;&#125;&quot;.format(fp))</div></pre></td></tr></table></figure>
<p>一旦你加上了这些代码,你可以运行<code>python predict.py</code>来生成预测. 运行上面的代码给予我们假的负样本率为<code>.26</code>,也就是说对于止赎贷款来说,我们错误地预测了<code>26%</code>.这是个好的开始,但我们还可以做很多提升!</p>
<p>完整的<code>predict.py</code>文件在<a href="https://github.com/dataquestio/loan-prediction/blob/master/predict.py" target="_blank" rel="external">这里</a></p>
<p>你现在的文件树应该长这样:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">loan-prediction</div><div class="line">├── data</div><div class="line">│   ├── Acquisition_2012Q1.txt</div><div class="line">│   ├── Acquisition_2012Q2.txt</div><div class="line">│   ├── Performance_2012Q1.txt</div><div class="line">│   ├── Performance_2012Q2.txt</div><div class="line">│   └── ...</div><div class="line">├── processed</div><div class="line">│   ├── Acquisition.txt</div><div class="line">│   ├── Performance.txt</div><div class="line">│   ├── train.csv</div><div class="line">├── .gitignore</div><div class="line">├── annotate.py</div><div class="line">├── assemble.py</div><div class="line">├── predict.py</div><div class="line">├── README.md</div><div class="line">├── requirements.txt</div><div class="line">├── settings.py</div></pre></td></tr></table></figure>
<h1 id="写一个README"><a href="#写一个README" class="headerlink" title="写一个README"></a>写一个README</h1><p>既然我们已经完成了我们的项目, 我们只需要写一个<code>README.md</code>文件,让其他人知道我们做了什么,以及如何复制它.一个典型的<code>README.md</code>应该包括以下内容:</p>
<ul>
<li>一个高屋建瓴的项目概览,以及目标是什么</li>
<li>哪里去下载所需的数据和材料</li>
<li>安装教程<ul>
<li>如何安装需要的模块</li>
</ul>
</li>
<li>使用教程<ul>
<li>如何运行项目</li>
<li>每一步应该看到哪些结果</li>
</ul>
</li>
<li>如何向这个项目做贡献<ul>
<li>扩展这个项目的好的下一步</li>
</ul>
</li>
</ul>
<p><a href="https://github.com/dataquestio/loan-prediction/blob/master/README.md" target="_blank" rel="external">这里</a>是本项目的一个样本<code>README.md</code></p>
<h1 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h1><p>恭喜,你已经完成了一个从头到文的机器学习项目!你可在<a href="https://github.com/dataquestio/loan-prediction" target="_blank" rel="external">这里</a>找到完整的样本项目.你完成项目之后,上传到Github上会是个好主意,这样其他人就会看到这是你作品集的一部分.</p>
<p>这些数据尚有一些地方待你挖掘.大致来说,我们可以把它们分成<code>3</code>类 – 延展项目,把它做得更准确, 找到其他数据来预测, 探索数据. 这里有一些想法:</p>
<ul>
<li>用<code>annotate.py</code>生成更多特征</li>
<li>在<code>predict.py</code>里换个算法</li>
<li>使用Fannie Mae里的更多数据</li>
<li>加上一个预测未来数据的方法.现在我们写的代码在我们加上更多数据时也会运行,所以我们可以加上更多过去的或者未来的数据</li>
<li>尝试能不能预测银行一开始该不该放出贷款(vs Fannie Mae应不应该收购贷款)<ul>
<li>删除那些银行在发放贷款时不能获得的信息<ul>
<li>一些列是在Fannie Mae收购的时候有的,但之前没有</li>
</ul>
</li>
<li>做预测</li>
</ul>
</li>
<li>探索一下看你能不能预测除了<code>foreclosure_status</code>以外的数据<ul>
<li>你能不能预测房产在发售的时候卖多少钱?</li>
</ul>
</li>
<li>探索一下表现数据更新时的细节<ul>
<li>你能不能预测借方迟付贷款的次数?</li>
<li>你能不能画出典型的贷款周期?</li>
</ul>
</li>
<li>把数据按州分类,或者按邮政编码分类<ul>
<li>你有看到一些有趣的模式吗?</li>
</ul>
</li>
</ul>
<p>如果你建立了一些有趣的项目, 请在留言区让我们知道!</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/21/data-sceince-portfolio-machine-learning-project/" data-id="civ12avkm0003c7ay0c7z7lj4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/09/26/data-sceince-portfolio-machine-learning-project/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2016/09/18/the_annoying_jupyter_notebook/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">jupyter notebook调用不同environment解决方案</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jupyter-Notebook-Environment-Anaconda/">Jupyter Notebook Environment Anaconda</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Jupyter-Notebook-Environment-Anaconda/" style="font-size: 10px;">Jupyter Notebook Environment Anaconda</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/02/tensorflow-few-operations/">tensorflow_few_operations</a>
          </li>
        
          <li>
            <a href="/2016/10/31/question-diff-privacy/">question_diff_privacy</a>
          </li>
        
          <li>
            <a href="/2016/09/26/data-sceince-portfolio-machine-learning-project/">(no title)</a>
          </li>
        
          <li>
            <a href="/2016/09/21/data-sceince-portfolio-machine-learning-project/">构建数据科学的作品集：从机器学习项目开始</a>
          </li>
        
          <li>
            <a href="/2016/09/18/the_annoying_jupyter_notebook/">jupyter notebook调用不同environment解决方案</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Tang Xiaoting<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>